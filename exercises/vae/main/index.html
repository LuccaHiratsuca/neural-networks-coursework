<!DOCTYPE html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Coursework for the Neural Networks class at Insper, São Paulo, Brazil."><meta name=author content="Lucca Hiratsuca Costa"><link href=https://luccahiratsuca.github.io/neural-networks-coursework/exercises/vae/main/ rel=canonical><link href=../../mlp/main/ rel=prev><link href=../../../classification-project/main/ rel=next><link rel=icon href=../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.0"><title>VAE Task - Neural Networks Coursework</title><link rel=stylesheet href=../../../assets/stylesheets/main.618322db.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.ab4e12ef.min.css><style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M64%20480c-35.3%200-64-28.7-64-64V96c0-35.3%2028.7-64%2064-64h320c35.3%200%2064%2028.7%2064%2064v213.5c0%2017-6.7%2033.3-18.7%2045.3L322.7%20461.3c-12%2012-28.3%2018.7-45.3%2018.7zm325.5-176H296c-13.3%200-24%2010.7-24%2024v93.5z%22/%3E%3C/svg%3E');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M384%20512H96c-53%200-96-43-96-96V96C0%2043%2043%200%2096%200h304c26.5%200%2048%2021.5%2048%2048v288c0%2020.9-13.4%2038.7-32%2045.3V448c17.7%200%2032%2014.3%2032%2032s-14.3%2032-32%2032zM96%20384c-17.7%200-32%2014.3-32%2032s14.3%2032%2032%2032h256v-64zm32-232c0%2013.3%2010.7%2024%2024%2024h176c13.3%200%2024-10.7%2024-24s-10.7-24-24-24H152c-13.3%200-24%2010.7-24%2024m24%2072c-13.3%200-24%2010.7-24%2024s10.7%2024%2024%2024h176c13.3%200%2024-10.7%2024-24s-10.7-24-24-24z%22/%3E%3C/svg%3E');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M256%20512a256%20256%200%201%200%200-512%20256%20256%200%201%200%200%20512m-32-352a32%2032%200%201%201%2064%200%2032%2032%200%201%201-64%200m-8%2064h48c13.3%200%2024%2010.7%2024%2024v88h8c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-80c-13.3%200-24-10.7-24-24s10.7-24%2024-24h24v-64h-24c-13.3%200-24-10.7-24-24s10.7-24%2024-24%22/%3E%3C/svg%3E');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M461.2%2018.9C472.7%2024%20480%2035.4%20480%2048v416c0%2012.6-7.3%2024-18.8%2029.1s-24.8%203.2-34.3-5.1l-46.6-40.7c-43.6-38.1-98.7-60.3-156.4-63V480c0%2017.7-14.3%2032-32%2032h-32c-17.7%200-32-14.3-32-32v-96C57.3%20384%200%20326.7%200%20256s57.3-128%20128-128h84.5c61.8-.2%20121.4-22.7%20167.9-63.3L427%2024c9.4-8.3%2022.9-10.2%2034.3-5.1zM224%20320v.2c70.3%202.7%20137.8%2028.5%20192%2073.4V118.3c-54.2%2044.9-121.7%2070.7-192%2073.4z%22/%3E%3C/svg%3E');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M434.8%2070.1c14.3%2010.4%2017.5%2030.4%207.1%2044.7l-256%20352c-5.5%207.6-14%2012.3-23.4%2013.1s-18.5-2.7-25.1-9.3l-128-128c-12.5-12.5-12.5-32.8%200-45.3s32.8-12.5%2045.3%200l101.5%20101.5%20234-321.7c10.4-14.3%2030.4-17.5%2044.7-7.1z%22/%3E%3C/svg%3E');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M256%20512a256%20256%200%201%200%200-512%20256%20256%200%201%200%200%20512m0-336c-17.7%200-32%2014.3-32%2032%200%2013.3-10.7%2024-24%2024s-24-10.7-24-24c0-44.2%2035.8-80%2080-80s80%2035.8%2080%2080c0%2047.2-36%2067.2-56%2074.5v3.8c0%2013.3-10.7%2024-24%2024s-24-10.7-24-24v-8.1c0-20.5%2014.8-35.2%2030.1-40.2%206.4-2.1%2013.2-5.5%2018.2-10.3%204.3-4.2%207.7-10%207.7-19.6%200-17.7-14.3-32-32-32zm-32%20192a32%2032%200%201%201%2064%200%2032%2032%200%201%201-64%200%22/%3E%3C/svg%3E');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M256%200c14.7%200%2028.2%208.1%2035.2%2021l216%20400c6.7%2012.4%206.4%2027.4-.8%2039.5S486.1%20480%20472%20480H40c-14.1%200-27.2-7.4-34.4-19.5s-7.5-27.1-.8-39.5l216-400c7-12.9%2020.5-21%2035.2-21m0%20352a32%2032%200%201%200%200%2064%2032%2032%200%201%200%200-64m0-192c-18.2%200-32.7%2015.5-31.4%2033.7l7.4%20104c.9%2012.5%2011.4%2022.3%2023.9%2022.3%2012.6%200%2023-9.7%2023.9-22.3l7.4-104c1.3-18.2-13.1-33.7-31.4-33.7z%22/%3E%3C/svg%3E');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20576%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M480-16c6.9%200%2013%204.4%2015.2%2010.9l13.5%2040.4%2040.4%2013.5C555.6%2051%20560%2057.1%20560%2064s-4.4%2013-10.9%2015.2l-40.4%2013.5-13.5%2040.4c-2.2%206.5-8.3%2010.9-15.2%2010.9s-13-4.4-15.2-10.9l-13.5-40.4-40.4-13.5C404.4%2077%20400%2070.9%20400%2064s4.4-13%2010.9-15.2l40.4-13.5%2013.5-40.4C467-11.6%20473.1-16%20480-16M321.4%2097.4c12.5-12.5%2032.8-12.5%2045.3%200l80%2080c12.5%2012.5%2012.5%2032.8%200%2045.3l-10.9%2010.9c7.9%2022%2012.2%2045.7%2012.2%2070.5%200%20114.9-93.1%20208-208%20208S32%20418.9%2032%20304%20125.1%2096%20240%2096c24.7%200%2048.5%204.3%2070.5%2012.3zM144%20304c0-53%2043-96%2096-96%2013.3%200%2024-10.7%2024-24s-10.7-24-24-24c-79.5%200-144%2064.5-144%20144%200%2013.3%2010.7%2024%2024%2024s24-10.7%2024-24%22/%3E%3C/svg%3E');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M416%20427.4c58.5-44%2096-111.6%2096-187.4C512%20107.5%20397.4%200%20256%200S0%20107.5%200%20240c0%2075.8%2037.5%20143.4%2096%20187.4V464c0%2026.5%2021.5%2048%2048%2048h32v-40c0-13.3%2010.7-24%2024-24s24%2010.7%2024%2024v40h64v-40c0-13.3%2010.7-24%2024-24s24%2010.7%2024%2024v40h32c26.5%200%2048-21.5%2048-48zM96%20256a64%2064%200%201%201%20128%200%2064%2064%200%201%201-128%200m256-64a64%2064%200%201%201%200%20128%2064%2064%200%201%201%200-128%22/%3E%3C/svg%3E');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20640%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M352%200c0-17.7-14.3-32-32-32s-32%2014.3-32%2032v64h-96c-53%200-96%2043-96%2096v224c0%2053%2043%2096%2096%2096h256c53%200%2096-43%2096-96V160c0-53-43-96-96-96h-96zM160%20368c0-13.3%2010.7-24%2024-24h32c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-32c-13.3%200-24-10.7-24-24m120%200c0-13.3%2010.7-24%2024-24h32c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-32c-13.3%200-24-10.7-24-24m120%200c0-13.3%2010.7-24%2024-24h32c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-32c-13.3%200-24-10.7-24-24M224%20176a48%2048%200%201%201%200%2096%2048%2048%200%201%201%200-96m144%2048a48%2048%200%201%201%2096%200%2048%2048%200%201%201-96%200m-304%200c0-17.7-14.3-32-32-32S0%20206.3%200%20224v96c0%2017.7%2014.3%2032%2032%2032s32-14.3%2032-32zm544-32c-17.7%200-32%2014.3-32%2032v96c0%2017.7%2014.3%2032%2032%2032s32-14.3%2032-32v-96c0-17.7-14.3-32-32-32%22/%3E%3C/svg%3E');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M288%200H128c-17.7%200-32%2014.3-32%2032s14.3%2032%2032%2032v151.5L7.5%20426.3C2.6%20435%200%20444.7%200%20454.7%200%20486.4%2025.6%20512%2057.3%20512h333.4c31.6%200%2057.3-25.6%2057.3-57.3%200-10-2.6-19.8-7.5-28.4L320%20215.5V64c17.7%200%2032-14.3%2032-32S337.7%200%20320%200zm-96%20215.5V64h64v151.5c0%2011.1%202.9%2022.1%208.4%2031.8L306%20320H142l41.6-72.7c5.5-9.7%208.4-20.6%208.4-31.8%22/%3E%3C/svg%3E');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M0%20216C0%20149.7%2053.7%2096%20120%2096h8c17.7%200%2032%2014.3%2032%2032s-14.3%2032-32%2032h-8c-30.9%200-56%2025.1-56%2056v8h64c35.3%200%2064%2028.7%2064%2064v64c0%2035.3-28.7%2064-64%2064H64c-35.3%200-64-28.7-64-64zm256%200c0-66.3%2053.7-120%20120-120h8c17.7%200%2032%2014.3%2032%2032s-14.3%2032-32%2032h-8c-30.9%200-56%2025.1-56%2056v8h64c35.3%200%2064%2028.7%2064%2064v64c0%2035.3-28.7%2064-64%2064h-64c-35.3%200-64-28.7-64-64z%22/%3E%3C/svg%3E');}</style><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../assets/_markdown_exec_pyodide.css><link rel=stylesheet href=../../../assets/_markdown_exec_ansi.css><link rel=stylesheet href=../../../assets/stylesheets/badge.css><link rel=stylesheet href=../../../termynal.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><link href=../../../assets/stylesheets/glightbox.min.css rel=stylesheet><script src=../../../assets/javascripts/glightbox.min.js></script><style id=glightbox-style>
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=grey data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#variational-autoencoder-on-mnist class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="Neural Networks Coursework" class="md-header__button md-logo" aria-label="Neural Networks Coursework" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Neural Networks Coursework </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> VAE Task </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=grey data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"></path></svg> </label> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=grey data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"></path></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=grey data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_3 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"></path></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=grey data-md-color-accent=indigo aria-label="Switch to system preference" type=radio name=__palette id=__palette_3> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"></path></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/luccahiratsuca/neural-networks-coursework title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg> </div> <div class=md-source__repository> github/neural-networks-coursework </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="Neural Networks Coursework" class="md-nav__button md-logo" aria-label="Neural Networks Coursework" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg> </a> Neural Networks Coursework </label> <div class=md-nav__source> <a href=https://github.com/luccahiratsuca/neural-networks-coursework title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg> </div> <div class=md-source__repository> github/neural-networks-coursework </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex> <span class=md-ellipsis> Exercises </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Exercises </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../data/main/ class=md-nav__link> <span class=md-ellipsis> Data Task </span> </a> </li> <li class=md-nav__item> <a href=../../perceptron/main/ class=md-nav__link> <span class=md-ellipsis> Perceptron Task </span> </a> </li> <li class=md-nav__item> <a href=../../mlp/main/ class=md-nav__link> <span class=md-ellipsis> MLP Task </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> VAE Task </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> VAE Task </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-introduction class=md-nav__link> <span class=md-ellipsis> 1. Introduction </span> </a> </li> <li class=md-nav__item> <a href=#2-dataset class=md-nav__link> <span class=md-ellipsis> 2. Dataset </span> </a> <nav class=md-nav aria-label="2. Dataset"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#21-description class=md-nav__link> <span class=md-ellipsis> 2.1. Description </span> </a> </li> <li class=md-nav__item> <a href=#22-preprocessing class=md-nav__link> <span class=md-ellipsis> 2.2. Preprocessing </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#3-vae-architecture class=md-nav__link> <span class=md-ellipsis> 3. VAE Architecture </span> </a> <nav class=md-nav aria-label="3. VAE Architecture"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#31-encoder class=md-nav__link> <span class=md-ellipsis> 3.1. Encoder </span> </a> </li> <li class=md-nav__item> <a href=#32-reparameterization-trick class=md-nav__link> <span class=md-ellipsis> 3.2. Reparameterization Trick </span> </a> </li> <li class=md-nav__item> <a href=#33-decoder class=md-nav__link> <span class=md-ellipsis> 3.3. Decoder </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#4-loss-function class=md-nav__link> <span class=md-ellipsis> 4. Loss Function </span> </a> <nav class=md-nav aria-label="4. Loss Function"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#41-reconstruction-loss class=md-nav__link> <span class=md-ellipsis> 4.1. Reconstruction Loss </span> </a> </li> <li class=md-nav__item> <a href=#42-kl-divergence class=md-nav__link> <span class=md-ellipsis> 4.2. KL Divergence </span> </a> </li> <li class=md-nav__item> <a href=#43-total-loss class=md-nav__link> <span class=md-ellipsis> 4.3. Total Loss </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#both-terms-work-together-bce-ensures-accurate-reconstruction-kl-regularizes-the-latent-space class=md-nav__link> <span class=md-ellipsis> Both terms work together: BCE ensures accurate reconstruction; KL regularizes the latent space. </span> </a> </li> <li class=md-nav__item> <a href=#5-training-procedure class=md-nav__link> <span class=md-ellipsis> 5. Training Procedure </span> </a> <nav class=md-nav aria-label="5. Training Procedure"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#51-optimizer-hyperparameters class=md-nav__link> <span class=md-ellipsis> 5.1. Optimizer &amp; Hyperparameters </span> </a> </li> <li class=md-nav__item> <a href=#52-loop-summary class=md-nav__link> <span class=md-ellipsis> 5.2. Loop Summary </span> </a> </li> <li class=md-nav__item> <a href=#53-observed-behavior class=md-nav__link> <span class=md-ellipsis> 5.3. Observed Behavior </span> </a> </li> <li class=md-nav__item> <a href=#54-training-loss-curve class=md-nav__link> <span class=md-ellipsis> 5.4. Training Loss Curve </span> </a> <nav class=md-nav aria-label="5.4. Training Loss Curve"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#analysis class=md-nav__link> <span class=md-ellipsis> Analysis </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#6-results class=md-nav__link> <span class=md-ellipsis> 6. Results </span> </a> <nav class=md-nav aria-label="6. Results"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#61-reconstructed-images class=md-nav__link> <span class=md-ellipsis> 6.1. Reconstructed Images </span> </a> <nav class=md-nav aria-label="6.1. Reconstructed Images"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#interpretation class=md-nav__link> <span class=md-ellipsis> Interpretation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#62-latent-space-visualization class=md-nav__link> <span class=md-ellipsis> 6.2. Latent Space Visualization </span> </a> <nav class=md-nav aria-label="6.2. Latent Space Visualization"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#interpretation_1 class=md-nav__link> <span class=md-ellipsis> Interpretation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#63-generated-samples class=md-nav__link> <span class=md-ellipsis> 6.3. Generated Samples </span> </a> <nav class=md-nav aria-label="6.3. Generated Samples"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#interpretation_2 class=md-nav__link> <span class=md-ellipsis> Interpretation </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#7-discussion class=md-nav__link> <span class=md-ellipsis> 7. Discussion </span> </a> <nav class=md-nav aria-label="7. Discussion"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#71-latent-representation-quality class=md-nav__link> <span class=md-ellipsis> 7.1. Latent Representation Quality </span> </a> </li> <li class=md-nav__item> <a href=#72-reconstruction-vs-regularization-trade-off class=md-nav__link> <span class=md-ellipsis> 7.2. Reconstruction vs. Regularization Trade-off </span> </a> </li> <li class=md-nav__item> <a href=#73-limitations class=md-nav__link> <span class=md-ellipsis> 7.3. Limitations </span> </a> </li> <li class=md-nav__item> <a href=#74-potential-improvements class=md-nav__link> <span class=md-ellipsis> 7.4. Potential Improvements </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#8-conclusion class=md-nav__link> <span class=md-ellipsis> 8. Conclusion </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> Projects </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Projects </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../classification-project/main/ class=md-nav__link> <span class=md-ellipsis> Classification Project </span> </a> </li> <li class=md-nav__item> <a href=../../../regression-project/main/ class=md-nav__link> <span class=md-ellipsis> Regression Project </span> </a> </li> <li class=md-nav__item> <a href=../../../generative-project/main/ class=md-nav__link> <span class=md-ellipsis> Generative Project </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../thisdocumentation/main/ class=md-nav__link> <span class=md-ellipsis> This documentation </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-introduction class=md-nav__link> <span class=md-ellipsis> 1. Introduction </span> </a> </li> <li class=md-nav__item> <a href=#2-dataset class=md-nav__link> <span class=md-ellipsis> 2. Dataset </span> </a> <nav class=md-nav aria-label="2. Dataset"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#21-description class=md-nav__link> <span class=md-ellipsis> 2.1. Description </span> </a> </li> <li class=md-nav__item> <a href=#22-preprocessing class=md-nav__link> <span class=md-ellipsis> 2.2. Preprocessing </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#3-vae-architecture class=md-nav__link> <span class=md-ellipsis> 3. VAE Architecture </span> </a> <nav class=md-nav aria-label="3. VAE Architecture"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#31-encoder class=md-nav__link> <span class=md-ellipsis> 3.1. Encoder </span> </a> </li> <li class=md-nav__item> <a href=#32-reparameterization-trick class=md-nav__link> <span class=md-ellipsis> 3.2. Reparameterization Trick </span> </a> </li> <li class=md-nav__item> <a href=#33-decoder class=md-nav__link> <span class=md-ellipsis> 3.3. Decoder </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#4-loss-function class=md-nav__link> <span class=md-ellipsis> 4. Loss Function </span> </a> <nav class=md-nav aria-label="4. Loss Function"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#41-reconstruction-loss class=md-nav__link> <span class=md-ellipsis> 4.1. Reconstruction Loss </span> </a> </li> <li class=md-nav__item> <a href=#42-kl-divergence class=md-nav__link> <span class=md-ellipsis> 4.2. KL Divergence </span> </a> </li> <li class=md-nav__item> <a href=#43-total-loss class=md-nav__link> <span class=md-ellipsis> 4.3. Total Loss </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#both-terms-work-together-bce-ensures-accurate-reconstruction-kl-regularizes-the-latent-space class=md-nav__link> <span class=md-ellipsis> Both terms work together: BCE ensures accurate reconstruction; KL regularizes the latent space. </span> </a> </li> <li class=md-nav__item> <a href=#5-training-procedure class=md-nav__link> <span class=md-ellipsis> 5. Training Procedure </span> </a> <nav class=md-nav aria-label="5. Training Procedure"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#51-optimizer-hyperparameters class=md-nav__link> <span class=md-ellipsis> 5.1. Optimizer &amp; Hyperparameters </span> </a> </li> <li class=md-nav__item> <a href=#52-loop-summary class=md-nav__link> <span class=md-ellipsis> 5.2. Loop Summary </span> </a> </li> <li class=md-nav__item> <a href=#53-observed-behavior class=md-nav__link> <span class=md-ellipsis> 5.3. Observed Behavior </span> </a> </li> <li class=md-nav__item> <a href=#54-training-loss-curve class=md-nav__link> <span class=md-ellipsis> 5.4. Training Loss Curve </span> </a> <nav class=md-nav aria-label="5.4. Training Loss Curve"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#analysis class=md-nav__link> <span class=md-ellipsis> Analysis </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#6-results class=md-nav__link> <span class=md-ellipsis> 6. Results </span> </a> <nav class=md-nav aria-label="6. Results"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#61-reconstructed-images class=md-nav__link> <span class=md-ellipsis> 6.1. Reconstructed Images </span> </a> <nav class=md-nav aria-label="6.1. Reconstructed Images"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#interpretation class=md-nav__link> <span class=md-ellipsis> Interpretation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#62-latent-space-visualization class=md-nav__link> <span class=md-ellipsis> 6.2. Latent Space Visualization </span> </a> <nav class=md-nav aria-label="6.2. Latent Space Visualization"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#interpretation_1 class=md-nav__link> <span class=md-ellipsis> Interpretation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#63-generated-samples class=md-nav__link> <span class=md-ellipsis> 6.3. Generated Samples </span> </a> <nav class=md-nav aria-label="6.3. Generated Samples"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#interpretation_2 class=md-nav__link> <span class=md-ellipsis> Interpretation </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#7-discussion class=md-nav__link> <span class=md-ellipsis> 7. Discussion </span> </a> <nav class=md-nav aria-label="7. Discussion"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#71-latent-representation-quality class=md-nav__link> <span class=md-ellipsis> 7.1. Latent Representation Quality </span> </a> </li> <li class=md-nav__item> <a href=#72-reconstruction-vs-regularization-trade-off class=md-nav__link> <span class=md-ellipsis> 7.2. Reconstruction vs. Regularization Trade-off </span> </a> </li> <li class=md-nav__item> <a href=#73-limitations class=md-nav__link> <span class=md-ellipsis> 7.3. Limitations </span> </a> </li> <li class=md-nav__item> <a href=#74-potential-improvements class=md-nav__link> <span class=md-ellipsis> 7.4. Potential Improvements </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#8-conclusion class=md-nav__link> <span class=md-ellipsis> 8. Conclusion </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <nav class=md-path aria-label=Navigation> <ol class=md-path__list> <li class=md-path__item> <a href=../../.. class=md-path__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-path__item> <a href=../../data/main/ class=md-path__link> <span class=md-ellipsis> Exercises </span> </a> </li> </ol> </nav> <article class="md-content__inner md-typeset"> <h1 id=variational-autoencoder-on-mnist>Variational Autoencoder on MNIST</h1> <p>The notebook is available in the repository inside the <code>notebooks</code> folder.</p> <h2 id=1-introduction>1. Introduction</h2> <p>The goal of this project is to implement, train, and analyze a <strong>Variational Autoencoder (VAE)</strong> using the MNIST dataset.<br> A VAE is a generative model capable of learning a continuous latent representation of the data and generating new samples by decoding latent vectors.</p> <p>This report covers:</p> <ol> <li>Dataset and preprocessing </li> <li>VAE architecture (encoder, decoder, reparameterization) </li> <li>Loss function and training procedure </li> <li>Reconstruction of images </li> <li>Latent space visualization </li> <li>Generation of new samples </li> <li>Training loss analysis </li> <li>Discussion and conclusion </li> </ol> <p>All experiments were implemented in <strong>PyTorch</strong>.</p> <hr> <h2 id=2-dataset>2. Dataset</h2> <h3 id=21-description>2.1. Description</h3> <p>The project uses the <strong>MNIST</strong> dataset, which contains:</p> <ul> <li>60,000 training images </li> <li>10,000 test images </li> <li>Grayscale handwritten digits (0–9) </li> <li>Resolution: <strong>28 × 28 pixels</strong></li> </ul> <p>MNIST is ideal for evaluating generative models due to its simplicity and structure.</p> <h3 id=22-preprocessing>2.2. Preprocessing</h3> <p>To ensure compatibility with Binary Cross-Entropy (BCE) reconstruction loss, images were only converted to tensors:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=n>transform</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>()</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=err>````</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=n>This</span> <span class=n>keeps</span> <span class=n>pixel</span> <span class=n>intensities</span> <span class=ow>in</span> <span class=n>the</span> <span class=nb>range</span> <span class=o>**</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>**</span><span class=p>,</span> <span class=k>as</span> <span class=n>required</span> <span class=n>by</span> <span class=n>BCE</span><span class=o>.</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=n>The</span> <span class=n>dataset</span> <span class=n>was</span> <span class=n>loaded</span> <span class=n>using</span><span class=p>:</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a><span class=err>```</span><span class=n>python</span>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a><span class=n>datasets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s2>"./data"</span><span class=p>,</span> <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=n>transform</span><span class=p>)</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=n>datasets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s2>"./data"</span><span class=p>,</span> <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=n>transform</span><span class=p>)</span>
</span></code></pre></div> <p>Batch size was set to <strong>128</strong>.</p> <hr> <h2 id=3-vae-architecture>3. VAE Architecture</h2> <p>A Variational Autoencoder consists of:</p> <ol> <li><strong>Encoder</strong> → maps input image to latent distribution parameters (μ and log σ²)</li> <li><strong>Reparameterization Trick</strong> → samples latent vector z in a differentiable way</li> <li><strong>Decoder</strong> → reconstructs images from latent vectors</li> </ol> <p>The latent dimension was intentionally set to <strong>2</strong>, enabling direct visualization.</p> <hr> <h3 id=31-encoder>3.1. Encoder</h3> <p>The encoder processes a flattened 784-dimensional vector (28×28) using:</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>Linear(784 → 400) → ReLU
</span></code></pre></div> <p>From this representation, two linear layers output:</p> <ul> <li><strong>μ (mu)</strong></li> <li><strong>log σ² (logvar)</strong></li> </ul> <p>These define the approximate posterior distribution:</p> <p><span class=arithmatex>\([q(z|x) = N(\mu, \sigma^2)]\)</span></p> <h3 id=32-reparameterization-trick>3.2. Reparameterization Trick</h3> <p>To allow gradient flow through the sampling operation, we rewrite:</p> <p><span class=arithmatex>\([ z = \mu + \sigma \odot \epsilon, \quad \epsilon \sim N(0, I) ]\)</span></p> <p>Implemented as:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=n>std</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=mf>0.5</span> <span class=o>*</span> <span class=n>logvar</span><span class=p>)</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=n>eps</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn_like</span><span class=p>(</span><span class=n>std</span><span class=p>)</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=n>z</span> <span class=o>=</span> <span class=n>mu</span> <span class=o>+</span> <span class=n>eps</span> <span class=o>*</span> <span class=n>std</span>
</span></code></pre></div> <h3 id=33-decoder>3.3. Decoder</h3> <p>The decoder reconstructs the image using:</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a>Linear(latent_dim → 400) → ReLU → Linear(400 → 784) → Sigmoid
</span></code></pre></div> <p>Sigmoid ensures the output is in <strong>[0,1]</strong>, matching the input range required for BCE.</p> <hr> <h2 id=4-loss-function>4. Loss Function</h2> <p>The VAE loss combines:</p> <ol> <li><strong>Reconstruction Loss (BCE)</strong></li> <li><strong>KL Divergence</strong> between the approximate posterior and the unit Gaussian prior.</li> </ol> <h3 id=41-reconstruction-loss>4.1. Reconstruction Loss</h3> <p><span class=arithmatex>\([ \text{BCE}(x, \hat{x}) = -\sum_i [x_i \log \hat{x}_i + (1-x_i)\log(1-\hat{x}_i)] ]\)</span></p> <h3 id=42-kl-divergence>4.2. KL Divergence</h3> <p><span class=arithmatex>\([ \text{KL}(q(z|x) || p(z)) = -\frac{1}{2} \sum_j (1 + \log\sigma_j^2 - \mu_j^2 - \sigma_j^2) ]\)</span></p> <h3 id=43-total-loss>4.3. Total Loss</h3> <p><span class=arithmatex>\([ \mathcal{L} = \text{BCE} + \text{KLD} ]\)</span></p> <h2 id=both-terms-work-together-bce-ensures-accurate-reconstruction-kl-regularizes-the-latent-space>Both terms work together: BCE ensures accurate reconstruction; KL regularizes the latent space.</h2> <h2 id=5-training-procedure>5. Training Procedure</h2> <h3 id=51-optimizer-hyperparameters>5.1. Optimizer &amp; Hyperparameters</h3> <ul> <li>Optimizer: <strong>Adam</strong></li> <li>Learning rate: <strong>1e-3</strong></li> <li>Epochs: <strong>20</strong></li> <li>Batch size: <strong>128</strong></li> <li>Device: <strong>CUDA</strong> when available</li> </ul> <h3 id=52-loop-summary>5.2. Loop Summary</h3> <p>Each training iteration:</p> <ol> <li>Forward pass: compute <code>x_hat</code>, <code>mu</code>, <code>logvar</code></li> <li>Compute loss</li> <li>Backpropagate gradients</li> <li>Update parameters</li> <li>Track epoch loss</li> </ol> <h3 id=53-observed-behavior>5.3. Observed Behavior</h3> <ul> <li>Steady decline in loss over epochs</li> <li>Convergence reached after ~15 epochs</li> <li>Smooth behavior indicates stable training</li> </ul> <h3 id=54-training-loss-curve>5.4. Training Loss Curve</h3> <p>The following plot shows the evolution of the total training loss over the 20 epochs:</p> <p><a class=glightbox data-type=image data-width=auto data-height=auto href=../images/training_loss.png data-desc-position=bottom><img alt="Training Loss" src=../images/training_loss.png></a></p> <h4 id=analysis>Analysis</h4> <ul> <li>The loss decreases monotonically, confirming successful optimization.</li> <li>The curve stabilizes near the end, indicating convergence.</li> <li>Slight noise is expected due to the stochastic KL component.</li> </ul> <p>Monitoring this curve is essential for verifying that the VAE is learning properly.</p> <hr> <h2 id=6-results>6. Results</h2> <h3 id=61-reconstructed-images>6.1. Reconstructed Images</h3> <p>The VAE was evaluated on test images. The figure below compares:</p> <ul> <li><strong>Top row:</strong> original inputs</li> <li><strong>Bottom row:</strong> reconstructions</li> </ul> <p><a class=glightbox data-type=image data-width=auto data-height=auto href=../images/reconstructions.png data-desc-position=bottom><img alt=Reconstructions src=../images/reconstructions.png></a></p> <h4 id=interpretation>Interpretation</h4> <ul> <li>The model captures digit shapes well.</li> <li>Some details are smoothed due to the small latent dimension (2).</li> <li>Reconstructions are coherent and readable.</li> </ul> <hr> <h3 id=62-latent-space-visualization>6.2. Latent Space Visualization</h3> <p>With a 2D latent space, each test image can be mapped to a point (z₁, z₂):</p> <p><a class=glightbox data-type=image data-width=auto data-height=auto href=../images/latent_space.png data-desc-position=bottom><img alt="Latent Space" src=../images/latent_space.png></a></p> <h4 id=interpretation_1>Interpretation</h4> <ul> <li>Digits form <strong>distinct clusters</strong>, showing class separation.</li> <li>Similar digits (e.g., 3 and 8) occupy nearby regions.</li> <li>The continuous manifold implies smooth interpolation is possible.</li> </ul> <p>This demonstrates that the VAE learned a meaningful structure of the data distribution.</p> <hr> <h3 id=63-generated-samples>6.3. Generated Samples</h3> <p>Random points were sampled from the prior distribution:</p> <p><span class=arithmatex>\([ z \sim N(0, I) ]\)</span></p> <p>Decoded images are shown below:</p> <p><a class=glightbox data-type=image data-width=auto data-height=auto href=../images/generated_samples.png data-desc-position=bottom><img alt="Generated Samples" src=../images/generated_samples.png></a></p> <h4 id=interpretation_2>Interpretation</h4> <ul> <li>Many samples resemble valid MNIST digits.</li> <li>Some are ambiguous—expected for a simple fully connected VAE.</li> <li>The model successfully <strong>generates new data</strong>, not seen during training.</li> </ul> <hr> <h2 id=7-discussion>7. Discussion</h2> <h3 id=71-latent-representation-quality>7.1. Latent Representation Quality</h3> <p>Using <code>latent_dim = 2</code> makes the learned structure easy to interpret. The latent clusters reveal:</p> <ul> <li>How the model organizes visual patterns</li> <li>Smooth transitions between digits</li> <li>Overlap between visually similar classes</li> </ul> <h3 id=72-reconstruction-vs-regularization-trade-off>7.2. Reconstruction vs. Regularization Trade-off</h3> <p>VAEs naturally balance:</p> <ul> <li>High reconstruction accuracy</li> <li>A smooth, well-behaved latent space</li> </ul> <p>Increasing reconstruction quality typically increases KL divergence, and vice versa.</p> <h3 id=73-limitations>7.3. Limitations</h3> <ul> <li>Latent space limited to 2 dimensions</li> <li>Fully-connected architecture lacks spatial modeling</li> <li>Reconstructions are blurrier than a convolutional VAE</li> </ul> <h3 id=74-potential-improvements>7.4. Potential Improvements</h3> <ul> <li>Replace dense layers with CNNs</li> <li>Increase latent dimension</li> <li>Experiment with <strong>β-VAE</strong> for disentanglement</li> <li>Train on Fashion-MNIST for more complex shapes</li> </ul> <hr> <h2 id=8-conclusion>8. Conclusion</h2> <p>This project successfully implemented a Variational Autoencoder for the MNIST dataset and demonstrated:</p> <ul> <li>Effective training and convergence</li> <li>Quality image reconstructions</li> <li>A well-structured 2D latent space</li> <li>Ability to generate novel, realistic digits</li> </ul> <p>The results confirm that VAEs are powerful tools for both <strong>representation learning</strong> and <strong>generative modeling</strong>. Even with a simple architecture and a very low-dimensional bottleneck, the model learns meaningful latent structure and produces convincing outputs.</p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"></path></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="October 27, 2025 02:57:23 UTC">October 27, 2025</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"></path></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="October 27, 2025 02:57:23 UTC">October 27, 2025</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Contributors> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 4a4 4 0 0 1 4 4 4 4 0 0 1-4 4 4 4 0 0 1-4-4 4 4 0 0 1 4-4m0 10c4.42 0 8 1.79 8 4v2H4v-2c0-2.21 3.58-4 8-4"></path></svg> </span> <nav> <a href=mailto:luccahiratsuca@gmail.com>Lucca Hiratsuca</a> </nav> </span> <span class=md-source-file__fact> <span class=md-icon title=Contributors> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path></svg> </span> <span>GitHub</span> <nav> <a href=https://github.com/LuccaHiratsuca class=md-author title=@LuccaHiratsuca> <img src="https://avatars.githubusercontent.com/u/104103173?v=4&size=72" alt=LuccaHiratsuca> </a> </nav> </span> </aside> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"annotate": null, "base": "../../..", "features": ["content.code.copy", "content.code.select", "content.code.annotate", "content.tooltips", "navigation.sections", "navigation.instant", "navigation.instant.progress", "navigation.top", "navigation.path", "navigation.tracking", "navigation.expand"], "search": "../../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../../assets/javascripts/bundle.e71a0d61.min.js></script> <script src=../../../assets/_markdown_exec_pyodide.js></script> <script src=../../../javascripts/mathjax.js></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://fastly.jsdelivr.net/npm/jquery/dist/jquery.min.js></script> <script src=https://fastly.jsdelivr.net/npm/echarts/dist/echarts.min.js></script> <script src=../../../assets/javascripts/badge.js async></script> <script src=../../../termynal.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>