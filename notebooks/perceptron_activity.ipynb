{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f9d66030",
      "metadata": {},
      "source": [
        "# Perceptron Activity \n",
        "\n",
        "This notebook solves the *Perceptron* activity end‑to‑end, following the assignment requirements and grading rubric. It includes:\n",
        "\n",
        "- Clear data generation for both exercises (1000 samples per class) using multivariate normal distributions.\n",
        "- A **from-scratch single-layer perceptron** trained with the classic online update rule (*NumPy-only for linear algebra*).\n",
        "- Visualizations: data scatter plots, decision boundaries overlaid on data, misclassified points, and **training accuracy vs. epoch**.\n",
        "- Discussion of results and how class separability affects convergence.\n",
        "\n",
        "> **Tooling restriction:** Only basic NumPy operations (e.g., dot products, additions) and Matplotlib for plotting are used. No ML libraries are used anywhere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "928c73b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, numpy as np, matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28fc8b49",
      "metadata": {},
      "source": [
        "## Reproducibility & Output Paths\n",
        "\n",
        "All figures are saved to a path required by the assignment’s publishing workflow:\n",
        "\n",
        "```python\n",
        "imgs = \"../docs/exercises/perceptron/images\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4cfc3ee1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images will be saved to: ../docs/exercises/perceptron/images\n"
          ]
        }
      ],
      "source": [
        "imgs = \"../docs/exercises/perceptron/images\"\n",
        "os.makedirs(imgs, exist_ok=True)\n",
        "print(\"Images will be saved to:\", imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1efee0eb",
      "metadata": {},
      "source": [
        "## 1. Helper Utilities\n",
        "\n",
        "Small utility functions for plotting and saving figures. We keep them intentionally simple and transparent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "87f6306c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _savefig(path):\n",
        "    \"\"\"Save the current Matplotlib figure to `path` with tight layout.\"\"\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path, dpi=160, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_scatter(X, y, title, path):\n",
        "    \"\"\"Scatter plot for two classes (0 as dots, 1 as x-marks).\"\"\"\n",
        "    plt.figure(figsize=(6,5))\n",
        "    m0, m1 = (y == 0), (y == 1)\n",
        "    plt.scatter(X[m0,0], X[m0,1], s=12, label=\"Class 0\")          \n",
        "    plt.scatter(X[m1,0], X[m1,1], s=12, label=\"Class 1\", marker=\"x\")\n",
        "    plt.xlabel(\"x1\") \n",
        "    plt.ylabel(\"x2\")\n",
        "    plt.title(title) \n",
        "    plt.legend()\n",
        "    _savefig(path)\n",
        "\n",
        "def decision_boundary_line(w, b):\n",
        "    \"\"\"Plot the line w·x + b = 0 on the current axes.\"\"\"\n",
        "    ax = plt.gca()\n",
        "    x_min, x_max = ax.get_xlim()\n",
        "    xs = np.linspace(x_min, x_max, 200)\n",
        "    if abs(w[1]) < 1e-9:\n",
        "        ax.axvline(-b/(w[0] + 1e-12), linestyle=\"--\", linewidth=2, label=\"w·x+b=0\")\n",
        "    else:\n",
        "        ys = -(w[0]*xs + b) / (w[1] + 1e-12)\n",
        "        ax.plot(xs, ys, linestyle=\"--\", linewidth=2, label=\"w·x+b=0\")\n",
        "\n",
        "def plot_with_boundary_and_errors(X, y, w, b, title, path):\n",
        "    \"\"\"Scatter data, draw decision boundary, and circle misclassified points.\"\"\"\n",
        "    plt.figure(figsize=(6,5))\n",
        "    m0, m1 = (y == 0), (y == 1)\n",
        "    plt.scatter(X[m0,0], X[m0,1], s=12, label=\"Class 0\")\n",
        "    plt.scatter(X[m1,0], X[m1,1], s=12, label=\"Class 1\", marker=\"x\")\n",
        "    # draw boundary\n",
        "    decision_boundary_line(w, b)\n",
        "    # misclassified markers (computed by caller to respect the perceptron decision)\n",
        "    plt.xlabel(\"x1\")\n",
        "    plt.ylabel(\"x2\")\n",
        "    plt.legend()\n",
        "    plt.title(title)\n",
        "    _savefig(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6dfb833",
      "metadata": {},
      "source": [
        "## 2. Data Generation (as specified)\n",
        "\n",
        "We generate two 2D Gaussian classes (1000 samples/class) with **fixed means** and **diagonal covariances** given in the activity.\n",
        "- Exercise 1: Well-separated means, **low variance** ⇒ almost linearly separable.\n",
        "- Exercise 2: Closer means, **higher variance** ⇒ partial overlap (not perfectly separable)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1800f1e9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2000, 2), (2000, 2))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def gen_ex1(rng):\n",
        "    \"\"\"Exercise 1 data: two Gaussians with low variance and distant means.\"\"\"\n",
        "    mean0 = np.array([1.5, 1.5])\n",
        "    cov0 = np.array([[0.5, 0.0],[0.0, 0.5]])\n",
        "    mean1 = np.array([5.0, 5.0])\n",
        "    cov1 = np.array([[0.5, 0.0],[0.0, 0.5]])\n",
        "    X0 = rng.multivariate_normal(mean0, cov0, size=1000)\n",
        "    X1 = rng.multivariate_normal(mean1, cov1, size=1000)\n",
        "    X = np.vstack([X0, X1])\n",
        "    y = np.concatenate([np.zeros(1000, int), np.ones(1000, int)])\n",
        "    return X, y\n",
        "\n",
        "def gen_ex2(rng):\n",
        "    \"\"\"Exercise 2 data: two Gaussians with higher variance and closer means.\"\"\"\n",
        "    mean0 = np.array([3.0, 3.0])\n",
        "    cov0 = np.array([[1.5, 0.0],[0.0, 1.5]])\n",
        "    mean1 = np.array([5.0, 5.0])\n",
        "    cov1 = np.array([[1.5, 0.0],[0.0, 1.5]])\n",
        "    X0 = rng.multivariate_normal(mean0, cov0, size=1000)\n",
        "    X1 = rng.multivariate_normal(mean1, cov1, size=1000)\n",
        "    X = np.vstack([X0, X1])\n",
        "    y = np.concatenate([np.zeros(1000, int), np.ones(1000, int)])\n",
        "    return X, y\n",
        "\n",
        "rng = np.random.default_rng(42)  # single seed for reproducibility across both exercises\n",
        "X1, y1 = gen_ex1(rng)\n",
        "X2, y2 = gen_ex2(rng)\n",
        "\n",
        "# Save and display initial scatter plots\n",
        "plot_scatter(X1, y1, \"Exercise1: Data Distribution\", f\"{imgs}/ex1_scatter.png\")\n",
        "plot_scatter(X2, y2, \"Exercise 2: Data Distribution\", f\"{imgs}/ex2_scatter.png\")\n",
        "\n",
        "X1.shape, X2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ced9ea8e",
      "metadata": {},
      "source": [
        "## 3. Perceptron (from scratch)\n",
        "\n",
        "We implement the **classic online perceptron** with a bias term. Labels are mapped to $\\{-1, +1\\}$ internally.  \n",
        "Update rule for a misclassified sample $(x, y)$ with $y \\in \\{-1,+1\\}$:\n",
        "\n",
        "$$\n",
        "\\mathbf{w} \\leftarrow \\mathbf{w} + \\eta\\, y\\, \\mathbf{x}, \\qquad\n",
        "b \\leftarrow b + \\eta\\, y.\n",
        "$$\n",
        "\n",
        "- Learning rate: $\\eta = 0.01$  \n",
        "- Stopping criteria: stop early if an epoch completes with **zero mistakes** or after **100 epochs**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ad7436a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Perceptron:\n",
        "    \"\"\"A simple online perceptron with bias (NumPy-only).\"\"\"\n",
        "    def __init__(self, eta=0.01, max_epochs=100, random_state=None):\n",
        "        self.eta = float(eta)\n",
        "        self.max_epochs = int(max_epochs)\n",
        "        self.random_state = random_state\n",
        "        self.w = None\n",
        "        self.b = 0.0\n",
        "        self.history = {\"acc\": []}\n",
        "        self.converged_epoch = None\n",
        "\n",
        "    def _init_params(self, d):\n",
        "        rng = np.random.default_rng(self.random_state)\n",
        "        self.w = rng.normal(scale=0.01, size=d)\n",
        "        self.b = 0.0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Train with online updates; record accuracy after each epoch.\"\"\"\n",
        "        y_signed = np.where(y == 1, 1, -1).astype(float)\n",
        "        n, d = X.shape\n",
        "        if self.w is None:\n",
        "            self._init_params(d)\n",
        "\n",
        "        self.history = {\"acc\": []}\n",
        "        self.converged_epoch = None\n",
        "\n",
        "        for epoch in range(self.max_epochs):\n",
        "            errors = 0\n",
        "            for i in range(n):\n",
        "                xi = X[i]\n",
        "                yi = y_signed[i]\n",
        "                activation = float(np.dot(self.w, xi) + self.b)\n",
        "                if yi * activation <= 0:  # misclassified or on the boundary\n",
        "                    self.w = self.w + self.eta * yi * xi\n",
        "                    self.b = self.b + self.eta * yi\n",
        "                    errors += 1\n",
        "\n",
        "            # track accuracy on the training set\n",
        "            preds = np.sign(X @ self.w + self.b)\n",
        "            acc = float((preds == y_signed).mean())\n",
        "            self.history[\"acc\"].append(acc)\n",
        "\n",
        "            if errors == 0:\n",
        "                self.converged_epoch = epoch + 1  # 1-based index for readability\n",
        "                break\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return (X @ self.w + self.b > 0).astype(int)\n",
        "\n",
        "    def accuracy(self, X, y):\n",
        "        return float((self.predict(X) == y).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a58e8536",
      "metadata": {},
      "source": [
        "## 4. Exercise 1 — Training, Decision Boundary, and Accuracy\n",
        "\n",
        "Given the strong linear separability, we expect fast convergence and near-perfect accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d649d994",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1.0, 34)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p1 = Perceptron(eta=0.01, max_epochs=100, random_state=123).fit(X1, y1)\n",
        "acc1 = p1.accuracy(X1, y1)\n",
        "\n",
        "# Decision boundary with misclassified points circled\n",
        "plt.figure(figsize=(6,5))\n",
        "m0, m1 = (y1 == 0), (y1 == 1)\n",
        "plt.scatter(X1[m0,0], X1[m0,1], s=12, label=\"Class 0\")\n",
        "plt.scatter(X1[m1,0], X1[m1,1], s=12, label=\"Class 1\", marker=\"x\")\n",
        "decision_boundary_line(p1.w, p1.b)\n",
        "\n",
        "y1_hat = p1.predict(X1)\n",
        "mis = y1_hat != y1\n",
        "if mis.any():\n",
        "    plt.scatter(X1[mis,0], X1[mis,1], facecolors=\"none\", edgecolors=\"k\", s=30, label=\"Misclassified\")\n",
        "\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.legend()\n",
        "plt.title(f\"Exercise 1: Decision Boundary (acc={acc1:.3f}, conv_epoch={p1.converged_epoch})\")\n",
        "_savefig(f\"{imgs}/ex1_boundary_miscl.png\")\n",
        "\n",
        "# Accuracy over epochs\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(range(1, len(p1.history[\"acc\"])+1), p1.history[\"acc\"], linewidth=2)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Exercise 1: Training Accuracy over Epochs\")\n",
        "_savefig(f\"{imgs}/ex1_accuracy.png\")\n",
        "\n",
        "acc1, p1.converged_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9619b386",
      "metadata": {},
      "source": [
        "**Exercise 1 Discussion.**  \n",
        "The classes are well separated and have low variance, so the perceptron quickly finds a separating hyperplane (a line in 2D). Convergence typically happens within a few epochs, and training accuracy is ~100%."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e89a3d79",
      "metadata": {},
      "source": [
        "## 5. Exercise 2 — Training, Decision Boundary, and Accuracy\n",
        "\n",
        "Here the classes overlap (closer means, higher variance). The dataset is **not perfectly separable**, so we do not expect 100% accuracy, and the perceptron may not strictly converge (zero mistakes) within 100 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5edd98b8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.503, None)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p2 = Perceptron(eta=0.01, max_epochs=100, random_state=321).fit(X2, y2)\n",
        "acc2 = p2.accuracy(X2, y2)\n",
        "\n",
        "# Decision boundary with misclassified points circled\n",
        "plt.figure(figsize=(6,5))\n",
        "m0, m1 = (y2 == 0), (y2 == 1)\n",
        "plt.scatter(X2[m0,0], X2[m0,1], s=12, label=\"Class 0\")\n",
        "plt.scatter(X2[m1,0], X2[m1,1], s=12, label=\"Class 1\", marker=\"x\")\n",
        "decision_boundary_line(p2.w, p2.b)\n",
        "\n",
        "y2_hat = p2.predict(X2)\n",
        "mis2 = y2_hat != y2\n",
        "if mis2.any():\n",
        "    plt.scatter(X2[mis2,0], X2[mis2,1], facecolors=\"none\", edgecolors=\"k\", s=30, label=\"Misclassified\")\n",
        "\n",
        "plt.xlabel(\"x1\"); plt.ylabel(\"x2\"); plt.legend()\n",
        "plt.title(f\"Exercise 2: Decision Boundary (acc={acc2:.3f}, conv_epoch={p2.converged_epoch})\")\n",
        "_savefig(f\"{imgs}/ex2_boundary_miscl.png\")\n",
        "\n",
        "# Accuracy over epochs\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(range(1, len(p2.history['acc'])+1), p2.history['acc'], linewidth=2)\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Exercise 2: Training Accuracy over Epochs\")\n",
        "_savefig(f\"{imgs}/ex2_accuracy.png\")\n",
        "\n",
        "acc2, p2.converged_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d19ca9",
      "metadata": {},
      "source": [
        "### 5.1 Multiple Random Initializations (Convergence Behavior)\n",
        "\n",
        "Because of overlap and non-separability, the final weights depend on initialization and data order. We run the perceptron **5 times** with different random seeds to visualize this effect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "32bb460e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([0.508, 0.508, 0.508, 0.5115, 0.5095], None)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "runs = 5\n",
        "accs, histories, params = [], [], []\n",
        "for seed in range(100, 100 + runs):\n",
        "    p = Perceptron(eta=0.01, max_epochs=100, random_state=seed).fit(X2, y2)\n",
        "    accs.append(p.accuracy(X2, y2))\n",
        "    histories.append(p.history[\"acc\"][:])\n",
        "    params.append((p.w.copy(), p.b, p.converged_epoch))\n",
        "\n",
        "# Plot accuracy curves from all runs\n",
        "plt.figure(figsize=(7,5))\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(range(1, len(h)+1), h, linewidth=1.5, label=f\"run {i+1}\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Exercise 2: Accuracy across 5 random initializations\")\n",
        "plt.legend()\n",
        "_savefig(f\"{imgs}/ex2_accuracy_multiruns.png\")\n",
        "\n",
        "# Boundary for the best run\n",
        "best_idx = int(np.argmax(accs))\n",
        "bw, bb, bconv = params[best_idx]\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.scatter(X2[y2==0,0], X2[y2==0,1], s=12, label=\"Class 0\")\n",
        "plt.scatter(X2[y2==1,0], X2[y2==1,1], s=12, label=\"Class 1\", marker=\"x\")\n",
        "\n",
        "# draw best boundary\n",
        "ax = plt.gca()\n",
        "x_min, x_max = ax.get_xlim(); xs = np.linspace(x_min, x_max, 200)\n",
        "if abs(bw[1]) < 1e-9:\n",
        "    ax.axvline(-bb/(bw[0] + 1e-12), linestyle=\"--\", linewidth=2, label=\"w·x+b=0 (best)\")\n",
        "else:\n",
        "    ys = -(bw[0]*xs + bb) / (bw[1] + 1e-12)\n",
        "    ax.plot(xs, ys, linestyle=\"--\", linewidth=2, label=\"w·x+b=0 (best)\")\n",
        "\n",
        "yb = (X2 @ bw + bb > 0).astype(int)\n",
        "mb = yb != y2\n",
        "if mb.any():\n",
        "    plt.scatter(X2[mb,0], X2[mb,1], facecolors=\"none\", edgecolors=\"k\", s=30, label=\"Misclassified\")\n",
        "plt.xlabel(\"x1\"); plt.ylabel(\"x2\"); plt.legend()\n",
        "plt.title(f\"Exercise 2 (Best of 5): Decision Boundary (acc={accs[best_idx]:.3f}, conv_epoch={bconv})\")\n",
        "_savefig(f\"{imgs}/ex2_best_boundary_miscl.png\")\n",
        "\n",
        "accs, bconv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7abe7ee",
      "metadata": {},
      "source": [
        "## 6. Analysis & Discussion\n",
        "\n",
        "- **Exercise 1 (Linearly separable):** The perceptron converges quickly (often within a handful of epochs) and achieves ~100% training accuracy. The decision boundary cleanly separates the classes because their means are far apart and covariance is small.\n",
        "- **Exercise 2 (Overlapping classes):** With closer means and higher variance, the classes are **not perfectly separable**. The perceptron cannot reach zero classification error on the training set and may not strictly “converge” (no-mistake epoch) within 100 epochs. Accuracy plateaus below 1.0 and depends on the random initialization.\n",
        "- **Takeaways:** The perceptron is guaranteed to converge only for linearly separable datasets. When separability is violated, it still finds a reasonable separating hyperplane but cannot eliminate all mistakes.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
